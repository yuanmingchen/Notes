##1、Adaptive Semi-supervised Learning for Cross-domainSentiment Classification

**会议**：EMNLP 2018

**论文链接**：[https://www.aclweb.org/anthology/D18-1383.pdf](https://www.aclweb.org/anthology/D18-1383.pdf)

### 1.1 动机：

提出两种方法，利用未标注数据学习目标领域的特定信息。【不需要任何目标领域的标注数据】

### 1.2、模型概要：

模型整体架构非常简单，就是一个文本编码器【CNN+最大池化】后面加一个分类器。编码器的目的是为了减小源领域和目标领域的差异性，以便让源领域尽可能多的知识可以适用于目标领域，以便两个领域可以共用一个分类器【第2个损失】，第1、3、4个损失都是针对分类器的，第1个损失针对的是分类器对源领域数据的分类性能，第3、4个损失针对的是分类器对目标领域数据的分类性能，也是作者提出的利用未标注的目标数据的两种方法。

- 1、第一个损失是源领域的分类损失【交叉熵损失】。这个损失是针对分类器对源领域数据的分类性能的限制。![image-20200319163153357](https://tva1.sinaimg.cn/large/00831rSTly1gczbksaesoj30o004ygm0.jpg)
- 2、 **Feature Adaptation**，源领域数据与目标领域数据在表示空间的距离。【类似JS散度的度量方式】该损失的作用是减小源领域和目标领域的差异性，以便两个领域可以共用一个分类器。这个损失是针对编码器部分的。![image-20200319163203920](https://tva1.sinaimg.cn/large/00831rSTly1gczbkxa4dkj30p60bq0tz.jpg)
- 3、**Domain Adaptive Semi-supervisedLearning (DAS)方法1——Entropy Minimization方法**。对于目标领域数据预测的熵损失：为了让预测结果更加”稀疏“，也就是最终预测的结果中，只有一个类别置信度非常高，其他类别的置信度非常低：增强模型预测的可信性。【注意到预测结果对所有类的预测概率都相等时，下面的损失是最大的】这个损失是针对分类器对目标领域数据的分类性能的限制。![image-20200319163217870](https://tva1.sinaimg.cn/large/00831rSTly1gczbl5pyjij30o604wt92.jpg)
- 4、**Domain Adaptive Semi-supervisedLearning (DAS)方法2——Self-ensemble Bootstrapping方法**。在第n轮时，把前n-1轮的预测结果【加权平均取one-hot】作为真实标签，与本轮的预测结果计算损失，反复迭代。该损失不仅可以利用无标注数据，还会要求模型在不同轮数的预测结果尽可能保持一致。这个损失是针对分类器对目标领域数据的分类性能的限制。![image-20200319163236936](https://tva1.sinaimg.cn/large/00831rSTly1gczblhhw5cj30me054mxj.jpg)

**算法整体流程**如下：

![image-20200319164341790](https://tva1.sinaimg.cn/large/00831rSTly1gczbx0tkpfj30ss0ysq8l.jpg)

### 1.3 数据说明

由于常用作标准数据集的亚马逊数据集删去了中性评论，作者认为这种数据集对他的模型有偏好【由于删去了不容易分辨情感的数据，只保留容易分辨的数据，这对于作者的损失3有帮助】，故而作者构建了自己的数据集，一个小规模一个大规模，set1表示有标注数据，set2表示无标注数据。set1数据完全均衡，set2是从大规模的真实数据中采样的，其分布于真实分布相似。

具体如下图所示：

![image-20200319170352618](https://tva1.sinaimg.cn/large/00831rSTly1gczci0mp6qj30nm0quadq.jpg)



### 1.4 实验结果

设置1：目标领域的set1作为目标领域的【无标注数据】训练使用。

设置2：源领域和目标领域的set2作为目标领域的【无标注数据】训练使用。

小规模数据均衡，故而采用准确率，大规模数据不均衡，采用宏平均F1。

![image-20200319170300287](https://tva1.sinaimg.cn/large/00831rSTly1gczchhvxmjj312z0u0jyv.jpg)





## 2、Adversarial Category Alignment Network for Cross-domainSentiment Classification

**论文地址**：[https://www.aclweb.org/anthology/N19-1258.pdf](https://www.aclweb.org/anthology/N19-1258.pdf)

**会议**：NAACL-HLT 2019

### 2.1 动机

以往的对抗学习方法侧重于通过欺骗领域判别器来对齐全局边际分布，而没有考虑特定类别的决策边界，这可能导致类别级特征的不匹配。 

通俗来讲，该论文通过对抗思想，使得目标领域的数据分布不仅整体上与源领域相似，而且具体到每一个类别来说，源领域和目标领域的数据分布也相似【更加细粒度地匹配源领域和目标领域的数据表示分布】，同时使得数据远离了分类的决策边界，消除了歧义数据，从而使得分类器的置信度更高。

### 2.2 模型

首先介绍一下作者的思想，如何使得目标领域数据与源领域数据在类别粒度上分布相似，并且让数据远离决策边界，变得更加线性可分？【可以参考下图理解作者的意图，下图左边展示的是对齐源领域和目标领域的整体边缘分布，右边在左边的基础上，对齐了源领域和目标领域每个类别的数据分布，相当于是整体分布内部的分布】

为此，作者设置了两个分类器F1和F2，这两个分类器对应两个决策边界，首先作者固定编码器G的参数，对于两个分类器来说，他们具有相同的分布，作者通过损失函数要求它们输出的概率分布的差异尽可能地大，强迫这两个分类器的输出差异更大，也就是图中的两条线距离更远。

此时再固定分类器，训练编码器，作者通过损失函数要求两个分类器输出的概率分布差异尽可能地小。由于两个分类器的差异很大，所以编码器必须调整自己对数据的表示，使得它们同时适应两个不同分类器，这样会强迫数据表示远离决策边界。

如此反复迭代，两个分类器的差异越来越大，数据表示距离决策边界越来越远，这就是编码器G和两个分类器的一个对抗过程。



![image-20200320131016081](https://tva1.sinaimg.cn/large/00831rSTgy1gd0bde4vjbj30pw0aata7.jpg)

下面是模型的整体流程：



![image-20200320131039136](https://tva1.sinaimg.cn/large/00831rSTgy1gd0bdo6gqaj31ia0q6dmt.jpg)



模型一共包含四个损失：

- 1、两个分类器的分类损失

![image-20200320133119484](https://tva1.sinaimg.cn/large/00831rSTgy1gd0bzc4w6wj30s20bqmyr.jpg)

- 2、DA问题中常见的一个距离损失，用于使得源领域和目标领域的数据表示距离更小。这个就是对齐整体边缘分布的过程了，对应于本节第一个图中的左半部分。

  ![image-20200320133239712](/Users/yuanmingchen/Library/Application Support/typora-user-images/image-20200320133239712.png)

- 3、其实这个对应两个损失，但是这两个损失是一组的【不能单独使用，否则失去对抗性】，并且仅差一个正负号，所以我放在一起了。下面的公式代表最后两个分类器输出的概率分布的距离损失，训练分类器时，最大化下面的距离【损失为负距离】，训练编码器G时，最小化下面的距离【损失为正距离】。这个就是对齐分布内部每个类别的分布的过程了，对应于本节第一个图中的右半部分。

  ![image-20200320133307927](https://tva1.sinaimg.cn/large/00831rSTgy1gd0c131gv1j30ju036wes.jpg)

  ![image-20200320133318505](https://tva1.sinaimg.cn/large/00831rSTgy1gd0c18ly0pj30rc05q74v.jpg)

- 4、目标领域预测的分布损失：其中sij=1表示i和j预测结果为同一类别，sij=0表示i和j预测结果为不同类别。该损失要求模型对于目标领域的数据，同一类别的数据预测分布差异尽可能小，不同类别的数据预测分布差异尽可能大。即使得目标领域数据更加线性可分。该损失可以进一步利用未标注数据。

  ![image-20200320133459238](https://tva1.sinaimg.cn/large/00831rSTgy1gd0c37atimj30oe05674f.jpg)

整体算法流程如下，首先利用损失1和2训练编码器和分类器，再使用对抗方法迭代训练分类器和编码器【注意每一步都需要分类损失】：

![image-20200320133429575](https://tva1.sinaimg.cn/large/00831rSTgy1gd0c2le7e7j30ry114dn3.jpg)

### 2.3 数据和实验结果

数据就是经典的亚马逊数据：

Baseline是只用了损失1，ACAN-KL使用了损失1和损失2，ACAN-KM使用了损失1、2、3，ACAN是全模型，使用了所有的损失。

值得注意的是，作者还提到了，如果不用损失2，直接使用损失1和3，会导致最终效果很差，准确率低于40%近似于瞎蒙，这是因为必须使用损失2先限制源领域和目标领域的整体边缘分布进行对齐，类别内部的细粒度分布对齐才有意义，否则会起到反作用。

![image-20200320133841338](https://tva1.sinaimg.cn/large/00831rSTgy1gd0c6yr2luj31iy0sa48k.jpg)



下图是数据表示可视化，目标数据的左边只用了1、2损失，右边是全模型。

可以看到，左边只对齐了边缘分布，目标数据的类别与源领域数据的类别进行了对齐，而右边不仅对齐了边缘分布，对于每一个类别来说也源领域和目标领域也进行了对齐，同时使得目标数据远离了决策边界：



![image-20200320133957088](https://tva1.sinaimg.cn/large/00831rSTgy1gd0c8avtk4j31j00ps1kx.jpg)

下图是一些领域特定次的对比，作者的模型提取出来更多的领域特定词：

![image-20200320134300400](https://tva1.sinaimg.cn/large/00831rSTgy1gd0cbguxnej31ju0rgwra.jpg)

下图显示了未标注数据和标注数据的数量比例对模型效果的影响：

![image-20200320134353806](https://tva1.sinaimg.cn/large/00831rSTgy1gd0ccesulfj31ks0pke7n.jpg)

## 3、Pivot Based Language Modeling for Improved Neural Domain Adaptation

**论文地址**：[https://www.aclweb.org/anthology/N18-1112.pdf](https://www.aclweb.org/anthology/N18-1112.pdf)

**会议**：NAACL-HLT 2018

### 3.1 动机

借助基于枢轴的方法和神经网络（NN）进行的表示学习已在自然语言处理领域适应方面取得了重大进展，但是，遵循这些方法的**大多数先前工作并未明确利用输入文本的结构**，并且其输出通常是整个文本的表示向量。 

在本文中，我们介绍了基于枢轴的语言模型（PBLM），这是一种将**基于枢轴的建模方式**和**基于NN建模方式**以结构感知的方式结合在一起的表示学习模型。 

特别是，我们的模型使用顺序NN（LSTM）处理文本中的信息，并且其输出由每个输入单词的上下文相关表示向量组成。

下图所示的例子，正面枢纽词多余负面枢纽词，但是整体是负面的。所以考虑文本结构信息【例如斜体的连词at first、however这些】十分重要。

![image-20200320135851922](https://tva1.sinaimg.cn/large/00831rSTgy1gd0cryed37j30oa0ayac2.jpg)

### 3.2 模型

如下图a所示的模型，即为作者提出的PBLM模型，该模型基于LSTM语言模型改造而成。LSTM语言模型的任务是预测下一个词，而PBLM的任务是预测下一个文本单位【字词短语句子都可以，根据需要设置】是不是枢纽，如果是，预测它，否则预测结果为None【即只关心枢纽，其他词不预测】。作者实际使用时，用的是unigram和bigram，所以可能会预测出一个词或则两个词。

图b和图c是作者使用PBLM的两种方式，即在PBLM后面再添加一个LSTM/CNN编码分类器。

具体训练时，作者使用两步训练的策略。首先使用图a所示的任务预训练PBLM模型，训好以后，固定PNLM的参数，训练后面的LSTM/CNN编码分类器。

第一步训练时，使用的是源领域和目标领域的未标注数据，第二部训练时，使用源领域的标注数据做情感分类任务。

![image-20200320140035706](https://tva1.sinaimg.cn/large/00831rSTgy1gd0ctrasa1j30pe158jvu.jpg)

### 3.3 数据

处理经典的亚马逊四个领域，作者还添加了一个领域的数据——航空服务。由于航空服务的差评比率明显高于亚马逊的四个领域，且亚马逊的四个领域针对的是产品，而航空针对的是服务，故而领域差异更大，更具有挑战性。

### 3.4实验结果

实验结果如下：注意NoSt表示用的不是LSTM/CNN这种分类器，而是直接将PBLM的各个时刻的数据平均之后去做分类，这一操作会丢失PBLM的结构信息，导致效果变差。

![image-20200320140646947](https://tva1.sinaimg.cn/large/00831rSTgy1gd0d07htz8j313w0u0tk3.jpg)

下图是PBLM训练损失和最终准确率的变化，可以看出两者关系密切，证明PBLM预训练确实对最终的跨领域分类有作用。

![image-20200320140939631](https://tva1.sinaimg.cn/large/00831rSTgy1gd0d36wp4pj30qu0tajvz.jpg)



